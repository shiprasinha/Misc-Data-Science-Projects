{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709a2cd6",
   "metadata": {},
   "source": [
    "# Data Science Salaries Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d60b6b",
   "metadata": {},
   "source": [
    "[Data & Description Source](https://www.kaggle.com/datasets/ruchi798/data-science-job-salaries?resource=download)\n",
    "\n",
    "**Column Description**\n",
    "- work_year: The year the salary was paid. <br>\n",
    "- experience_level: The experience level in the job during the year with the following possible values: <br>\n",
    "    1. EN = Entry-level / Junior <br>\n",
    "    2. MI = Mid-level / Intermediate <br>\n",
    "    3. SE = Senior-level / Expert <br>\n",
    "    4. EX = Executive-level / Director <br>\n",
    "- employment_type: The type of employement for the role: <br>\n",
    "    1. PT = Part-time <br> \n",
    "    2. FT = Full-time <br> \n",
    "    3. CT = Contract <br>\n",
    "    4. FL = Freelance <br>\n",
    "- job_title: The role worked in during the year.<br>\n",
    "- salary: The total gross salary amount paid.<br>\n",
    "- salary_currency: The currency of the salary paid as an ISO 4217 currency code.<br>\n",
    "- salary_in_usd: The salary in USD (FX rate divided by avg. USD rate for the respective year via fxdata.foorilla.com.<br>\n",
    "- employee_residence: Employee's primary country of residence in during the work year as an ISO 3166 country code. <br>\n",
    "- remote_ratio: The overall amount of work done remotely, possible values are as follows: <br>\n",
    "    1. 0 = No remote work (less than 20%) <br>\n",
    "    2. 50 = Partially remote <br>\n",
    "    3. 100 = Fully remote (more than 80%) <br>\n",
    "- company_location: The country of the employer's main office or contracting branch as an ISO 3166 country code. <br>\n",
    "- company_size: The average number of people that worked for the company during the year: <br>\n",
    "    1. S = less than 50 employees (small) <br>\n",
    "    2. M = 50 to 250 employees (medium) <br>\n",
    "    3. L = more than 250 employees (large) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db221984",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075f4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# For t-test, f-test\n",
    "import scipy.stats as stats\n",
    "\n",
    "# For z-test\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d1575",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f292ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_salaries = pd.read_csv('ds_salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04654b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79833</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>260000</td>\n",
       "      <td>USD</td>\n",
       "      <td>260000</td>\n",
       "      <td>JP</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>85000</td>\n",
       "      <td>GBP</td>\n",
       "      <td>109024</td>\n",
       "      <td>GB</td>\n",
       "      <td>50</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000</td>\n",
       "      <td>USD</td>\n",
       "      <td>20000</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  work_year experience_level employment_type  \\\n",
       "0           0       2020               MI              FT   \n",
       "1           1       2020               SE              FT   \n",
       "2           2       2020               SE              FT   \n",
       "3           3       2020               MI              FT   \n",
       "4           4       2020               SE              FT   \n",
       "\n",
       "                    job_title  salary salary_currency  salary_in_usd  \\\n",
       "0              Data Scientist   70000             EUR          79833   \n",
       "1  Machine Learning Scientist  260000             USD         260000   \n",
       "2           Big Data Engineer   85000             GBP         109024   \n",
       "3        Product Data Analyst   20000             USD          20000   \n",
       "4   Machine Learning Engineer  150000             USD         150000   \n",
       "\n",
       "  employee_residence  remote_ratio company_location company_size  \n",
       "0                 DE             0               DE            L  \n",
       "1                 JP             0               JP            S  \n",
       "2                 GB            50               GB            M  \n",
       "3                 HN             0               HN            S  \n",
       "4                 US            50               US            L  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_salaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d5b5f",
   "metadata": {},
   "source": [
    "### Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2843232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model data starts off as a pristine dataset from the raw data and then we do pre-processing on it\n",
    "hypothesis_data = raw_salaries.copy(deep=True)\n",
    "\n",
    "# Creating the job category column\n",
    "# Function to find the pattern and assign corresponding value\n",
    "def find_pattern(text, patterns):\n",
    "    text = text.lower()\n",
    "    for pattern, value in patterns.items():\n",
    "        match = re.findall(pattern, text)\n",
    "        if match:\n",
    "            return value\n",
    "    return text\n",
    "\n",
    "job_categories = {\n",
    "    r'data engineer': 'data engineer',\n",
    "    r'data analy': 'data analyst',\n",
    "    r'data scien': 'data scientist',\n",
    "    r'machine learning': 'machine learning',\n",
    "    r'ml engineer': 'machine learning'\n",
    "    \n",
    "}\n",
    "\n",
    "# Apply the function to the 'Text' column and assign the results to a new column 'NewColumn'\n",
    "hypothesis_data['job_category'] = hypothesis_data['job_title'].apply(find_pattern, patterns=job_categories)\n",
    "\n",
    "# Removing all columns that aren't needed for training or testing the models\n",
    "hypothesis_data.drop(columns=['Unnamed: 0', 'salary', 'job_title'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb55cc8",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Hypothesis testing means testing assumptions. These are the commonly used hypothesis tests.\n",
    "\n",
    "#### 1. T-test:<br>\n",
    "**Definition:**<br> \n",
    "A t-test is an inferential statistic used to determine if there is a significant difference between the means of two groups and how they are related. It is also used to check if the mean value of a sample is statistically similar to the mean value of the population if the sample is small (size<30 records).\n",
    "1. Assumptions: <br>\n",
    "    a. The datasets follow a normal distribution.<br>\n",
    "    b. Only mean of population is known.<br>\n",
    "    c. Sample size < 30<br>\n",
    "    d. Independent samples: The observations in each group are independent of each other. <br>\n",
    "    e. Homogeneity of variances: The variances of the two groups are equal. If this assumption is violated, alternative versions of the t-test, such as the Welch's t-test, can be used.<br>\n",
    "2. Both variables compared need to be continuous in nature.<br>\n",
    "\n",
    "[Youtube Link](https://www.youtube.com/watch?v=7UKKVSWp1Lg&list=PLOLWGEXpOrBx4ivtMfPvDyCjlok2OBk_w&index=6)<br>\n",
    "[T-test and types](https://www.investopedia.com/terms/t/t-test.asp)<br> \n",
    "\n",
    "#### 2. Z-Test:<br>\n",
    "**Definition**<br>\n",
    "The z-test calculates a z-statistic, which represents the number of standard deviations the sample mean is away from the population mean.<br>\n",
    "1. Assumptions: <br>\n",
    "    a. Both Mean and standard deviation of the population are known.<br>\n",
    "    b. Sample size > 30. If sample size > 30 then it will follow a normal distribution.<br>\n",
    "    c. Normality especially in smaller samples.<br>\n",
    "    d. Random sample.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f51668",
   "metadata": {},
   "source": [
    "### T-test\n",
    "\n",
    "**Hypothesis:** Data Science salaries are different than the mean of the population salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f83a0",
   "metadata": {},
   "source": [
    "Step 1: Create datasets to be compared. We are taking a small sample (n<30) because for larger samples we implement z-statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920ae80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets being compared\n",
    "all_salaries = hypothesis_data['salary_in_usd'] #population\n",
    "data_scientist_sal_sample = hypothesis_data.loc[hypothesis_data.job_category == 'data scientist','salary_in_usd']\\\n",
    "                            .sample(n=25, random_state=1) #sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "040f2cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average salary: 112297.86985172982\n",
      "Sample's avg. salary: 107091.44\n"
     ]
    }
   ],
   "source": [
    "print(f'Average salary: {all_salaries.mean()}')\n",
    "print(f'''Sample's avg. salary: {data_scientist_sal_sample.mean()}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97d8ed9",
   "metadata": {},
   "source": [
    "**Defining Ho & Ha**\n",
    "\n",
    "Ho: Mean Data Science Salary = 112300\n",
    "\n",
    "Ha: MeanData Science Salary != 112300\n",
    "    \n",
    "It is going to be a two-tailed t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b7dba",
   "metadata": {},
   "source": [
    "Step 2: Perform a simple t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de2e7697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=0.3608643574264332, pvalue=0.7183218184421127, df=630.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(all_salaries, data_scientist_sal_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1637cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reject null hypothesis - There is no significant difference between the means.\n"
     ]
    }
   ],
   "source": [
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(all_salaries, data_scientist_sal_sample)\n",
    "\n",
    "# Compare p-value with significance level\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis - There is a significant difference between the means.\")\n",
    "else:\n",
    "    print(\"Failed to reject null hypothesis - There is no significant difference between the means.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c13f35",
   "metadata": {},
   "source": [
    "### z-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b411f8e",
   "metadata": {},
   "source": [
    "**Hypothesis:** Data Science salaries are different than the mean of the population salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ec51b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reject null hypothesis - There is no significant difference from the population mean.\n"
     ]
    }
   ],
   "source": [
    "# Datasets being compared\n",
    "all_salaries = hypothesis_data['salary_in_usd'] #population\n",
    "data_scientist_sal_sample = hypothesis_data.loc[hypothesis_data.job_category == 'data scientist','salary_in_usd']\\\n",
    "                            .sample(n=50, random_state=1) #sample\n",
    "# Population mean and standard deviation\n",
    "population_mean = all_salaries.mean()\n",
    "population_std = all_salaries.std()\n",
    "\n",
    "# Perform one-sample z-test\n",
    "z_score, p_value = sm.stats.ztest(data_scientist_sal_sample, value=population_mean, alternative='two-sided')\n",
    "\n",
    "# Compare p-value with significance level\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis - There is a significant difference from the population mean.\")\n",
    "else:\n",
    "    print(\"Failed to reject null hypothesis - There is no significant difference from the population mean.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07265820",
   "metadata": {},
   "source": [
    "**Note:** The alternative parameter in sm.stats.ztest can take values: two-sided (for two tailed), larger (for right tailed z-test) and smaller (for left tailed z-test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70d52b",
   "metadata": {},
   "source": [
    "### Matched or Paired T-Test\n",
    "\n",
    "This hypothesis is done when the data contains before and after values for the same set of subjects. <br>\n",
    "Null Hypothesis: The process change has had no effect on subjects/ end metric <br>\n",
    "Alternative Hypothesis: The process change has effect on subjects/ end metric. <br>\n",
    "Some examples:\n",
    "    \n",
    "1. If a weight loss program has been effective. The data will contain before and after weights for the same people. <br>\n",
    "Value we will use for test: Xd (Difference) = After value - Before value\n",
    "H0: Mean of difference in before and after values >= 0 (Weight loss program has failed)\n",
    "Ha: Mean of Xd < 0 (Weight loss program helped subjects reduce weight)\n",
    "\n",
    "2. Has the change in prices of items affected their sales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6cf89f",
   "metadata": {},
   "source": [
    "### F-Test\n",
    "\n",
    "**Definition:**<br>\n",
    "Compare or hypothesis test on variances in the data between in populations. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2746b9a1",
   "metadata": {},
   "source": [
    "**Hypothesis 1:** \n",
    "\n",
    "H0: Variance of Data Scientist and Data Analyst salaries are similar. <br>\n",
    "Ha: Variance of Data Scientist and Data Analyst salaries are different. <br>\n",
    "\n",
    "Level of significance = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d4a008d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_statistic: 8.966934661369082; p_value: 0.002962789160360177 \n",
      "\n",
      "Reject null hypothesis - There are significant differences in the variances of the groups.\n"
     ]
    }
   ],
   "source": [
    "# Populations being compared\n",
    "data_scientist_salaries = hypothesis_data.loc[hypothesis_data.job_category == 'data scientist','salary_in_usd']\n",
    "data_analyst_salaries = hypothesis_data.loc[hypothesis_data.job_category == 'data analyst','salary_in_usd']\n",
    "\n",
    "# Perform F-test\n",
    "f_statistic, p_value = stats.f_oneway(data_scientist_salaries, data_analyst_salaries)\n",
    "\n",
    "print(f\"f_statistic: {f_statistic}; p_value: {p_value} \\n\")\n",
    "\n",
    "# Compare p-value with significance level (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis - There are significant differences in the variances of the groups.\")\n",
    "else:\n",
    "    print(\"Failed to reject null hypothesis - There are no significant differences in the variances of the groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9d7a3",
   "metadata": {},
   "source": [
    "**Hypothesis 2:** \n",
    "\n",
    "H0: Variance of Entry level and Executive level salaries are similar. <br>\n",
    "Ha: Variance of Entry level and Executive level salaries are different. <br>\n",
    "\n",
    "Level of significance = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67affb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_statistic: 82.9627895604364; p_value: 3.765360745681678e-15 \n",
      "\n",
      "Reject null hypothesis - There are significant differences in the variances of the groups.\n"
     ]
    }
   ],
   "source": [
    "# Populations being compared\n",
    "entry_level_salaries = hypothesis_data.loc[hypothesis_data.experience_level == 'EN','salary_in_usd']\n",
    "exec_level_salaries = hypothesis_data.loc[hypothesis_data.experience_level == 'EX','salary_in_usd']\n",
    "\n",
    "# Perform F-test\n",
    "f_statistic, p_value = stats.f_oneway(entry_level_salaries, exec_level_salaries)\n",
    "\n",
    "print(f\"f_statistic: {f_statistic}; p_value: {p_value} \\n\")\n",
    "\n",
    "# Compare p-value with significance level\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis - There are significant differences in the variances of the groups.\")\n",
    "else:\n",
    "    print(\"Failed to reject null hypothesis - There are no significant differences in the variances of the groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f27eb",
   "metadata": {},
   "source": [
    "### ANOVA test\n",
    "\n",
    "ANOVA is a statistical method used to compare the means of three or more groups to determine if there are significant differences among them. It is a broader framework that allows for the examination of variability among multiple groups simultaneously. ANOVA partitions the total variance in the data into two components: the variance between groups and the variance within groups.\n",
    "\n",
    "ANOVA utilizes F-test to assess the statistical significance of the observed differences wbetween group means.It compares the ratio of the mean square between groups to the mean square within groups, which is then used to calculate the F-statistic. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e907fae",
   "metadata": {},
   "source": [
    "Ex 1: Comparing the mean salaries of DS, DE and DA job categories.\n",
    "\n",
    "H0: Means of salaries within the DS, DE and DA job categories are same.<br>\n",
    "Ha: Means of salaries within the DS, DE and DA job categories are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce250453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject null hypothesis - There are significant differences in the means of the groups.\n"
     ]
    }
   ],
   "source": [
    "# Populations being compared\n",
    "data_scientist_salaries = hypothesis_data.loc[hypothesis_data.job_category == 'data scientist','salary_in_usd']\n",
    "data_engineer_salaries = hypothesis_data.loc[hypothesis_data.job_category == 'data engineer','salary_in_usd']\n",
    "data_analyst_salaries = hypothesis_data.loc[hypothesis_data.job_category == 'data analyst','salary_in_usd']\n",
    "\n",
    "# Perform F-test\n",
    "f_statistic, p_value = stats.f_oneway(data_scientist_salaries, data_engineer_salaries, data_analyst_salaries)\n",
    "\n",
    "# Compare p-value with significance level\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis - There are significant differences in the means of the groups.\")\n",
    "else:\n",
    "    print(\"Failed to reject null hypothesis - There are no significant differences in the means of the groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337309e",
   "metadata": {},
   "source": [
    "### Chi-squared test\n",
    "\n",
    "It is used to determine any relationship between two categorical variables. Some use cases of Chi-squared test are as below:\n",
    "\n",
    "1. Goodness-of-Fit Test:\n",
    "Determine if observed data fits a specified distribution or expected proportions.\n",
    "<br/>Example: Testing if the distribution of blood types in a population follows the expected proportions of A, B, AB, and O blood types.\n",
    "\n",
    "2. Test of Independence:\n",
    "Assess if there is an association or relationship between two categorical variables.\n",
    "<br/>Test Statistic: Pearson's chi-squared statistic.\n",
    "<br/>Example: Investigating if there is a significant relationship between smoking habits (smoker vs. non-smoker) and lung cancer occurrence (present vs. absent).\n",
    "\n",
    "3. Homogeneity Test:\n",
    "Compare the distributions or proportions of categorical variables across different populations or groups.\n",
    "<br/>Test Statistic: Pearson's chi-squared statistic.\n",
    "<br/>Example: Analyzing if the proportions of political party affiliation differ significantly across different age groups (e.g., young adults, middle-aged, elderly).\n",
    "\n",
    "4. Test of Association in Contingency Table:\n",
    "Determine if there is a significant relationship between two categorical variables in a contingency table.\n",
    "<br/>Example: Examining if there is an association between gender and preference for a particular brand (Brand A, Brand B, Brand C) based on survey data.\n",
    "\n",
    "5. Fisher's Exact Test:\n",
    "Determine the association between two categorical variables in a 2x2 contingency table when the sample sizes are small, and the Chi-square test may not be appropriate due to its reliance on asymptotic properties.  It is often applied in medical research, genetics, and other fields where small sample sizes are encountered. \n",
    "<br/>It is a non-parametric test that calculates the exact probability of observing the data, given the marginal totals, under the assumption of independence. It provides a p-value that indicates the likelihood of the observed values occuring due to sheer chance.\n",
    "<br/>Assumptions: <br/>Fisher's Exact test does not rely on any specific assumptions about the underlying distribution of the data. However, it assumes that the data are collected independently and that the sampling is random.\n",
    "<br/>Example: it can be used to assess if a particular treatment significantly affects the proportion of patients with a certain disease outcome.\n",
    "\n",
    "\n",
    "Steps for Analysis:\n",
    "<br/>a. Setup Hypotheses: Formulate the null and alternative hypotheses based on the research question.\n",
    "<br/>b. Create Contingency Table: Organize the observed data into a contingency table.\n",
    "<br/>c. Calculate Expected Frequencies: Compute the expected frequencies for each cell under the assumption of independence.\n",
    "<br/>d. Calculate Chi-Squared Statistic: Use the observed and expected frequencies to calculate the chi-squared statistic.\n",
    "<br/>e.Determine Significance: Compare the chi-squared statistic to a critical value from the chi-squared distribution or use a p-value to determine statistical significance.\n",
    "<br/>f. Interpret Results: Make conclusions based on the significance level and the context of the analysis.\n",
    "\n",
    "Source for the above information: Internet (ChatGPT)\n",
    "\n",
    "\n",
    "Q. Use cases \"Test of Independence\" and \"Test of Association in Contingency Table\" both sound similar. How do they differ?\n",
    "- Yes, both are used to determine association between categorical variables and use contingency tables. They differ on the basis of focus and context of the analysis.\n",
    "\n",
    "Test of Independence: User is interested in finding association between two categorical variables on the whole i.e show \"dependency\" between variables. The Observed values are usually represented by a 2 x 2 contingency table representing presence (True/1) or absence (False/0) of the two categories. For eg: \n",
    "<br/>Ex 1: Does a smoker (Smoker = 1) have higher chance of having Lung Cancer (Cancer = 1)\n",
    "<br/>Ex 2: Is a Female buyer (Female = 1) have a higher chance of buying a handbag (Buying Handbag = 1)\n",
    "\n",
    "\n",
    "Test of Association in Contingency Table: The contingency tables associated with this teast are of varying sizes. It is used to investigate \"association\" between two categorical variables. For eg: \n",
    "<br/>Ex 1: Association between genders (M/F/Other) and which brand they prefer.\n",
    "<br/>Ex 2: Age groups and what kind of candy they like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e828d",
   "metadata": {},
   "source": [
    "### Test of association in contingency table\n",
    "\n",
    "**Defining Null hypothesis and Alternative hypothesis**\n",
    "\n",
    "Ho: Employee residence is not associated with company location.\n",
    "\n",
    "Ha: Employee residence is asociated with company location.\n",
    "\n",
    "Level of confidence assumed = 95%\n",
    "Thus level of significance = 1 - 0.95 = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "506dc1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>employee_residence</th>\n",
       "      <th>AE</th>\n",
       "      <th>AR</th>\n",
       "      <th>AT</th>\n",
       "      <th>AU</th>\n",
       "      <th>BE</th>\n",
       "      <th>BG</th>\n",
       "      <th>BO</th>\n",
       "      <th>BR</th>\n",
       "      <th>CA</th>\n",
       "      <th>CH</th>\n",
       "      <th>...</th>\n",
       "      <th>RO</th>\n",
       "      <th>RS</th>\n",
       "      <th>RU</th>\n",
       "      <th>SG</th>\n",
       "      <th>SI</th>\n",
       "      <th>TN</th>\n",
       "      <th>TR</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>VN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "employee_residence  AE  AR  AT  AU  BE  BG  BO  BR  CA  CH  ...  RO  RS  RU  \\\n",
       "company_location                                            ...               \n",
       "AE                   3   0   0   0   0   0   0   0   0   0  ...   0   0   0   \n",
       "AS                   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   \n",
       "AT                   0   0   3   0   0   0   0   0   0   0  ...   0   0   0   \n",
       "AU                   0   0   0   3   0   0   0   0   0   0  ...   0   0   0   \n",
       "BE                   0   0   0   0   2   0   0   0   0   0  ...   0   0   0   \n",
       "\n",
       "employee_residence  SG  SI  TN  TR  UA  US  VN  \n",
       "company_location                                \n",
       "AE                   0   0   0   0   0   0   0  \n",
       "AS                   0   0   0   0   0   0   0  \n",
       "AT                   0   0   0   0   0   0   0  \n",
       "AU                   0   0   0   0   0   0   0  \n",
       "BE                   0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we create a contingency table containing observed values \n",
    "# for Company location and Employee Location from the dataset\n",
    "observed = pd.crosstab(hypothesis_data['company_location'], hypothesis_data['employee_residence'])\n",
    "observed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf2a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared value: 23187.380792483484\n",
      "P-value: 0.0\n",
      "Degrees of freedom (dof): 2744\n",
      "Expected values: [[1.48270181e-02 4.94233937e-03 1.48270181e-02 ... 4.94233937e-03\n",
      "  1.64085667e+00 1.48270181e-02]\n",
      " [4.94233937e-03 1.64744646e-03 4.94233937e-03 ... 1.64744646e-03\n",
      "  5.46952224e-01 4.94233937e-03]\n",
      " [1.97693575e-02 6.58978583e-03 1.97693575e-02 ... 6.58978583e-03\n",
      "  2.18780890e+00 1.97693575e-02]\n",
      " ...\n",
      " [4.94233937e-03 1.64744646e-03 4.94233937e-03 ... 1.64744646e-03\n",
      "  5.46952224e-01 4.94233937e-03]\n",
      " [1.75453048e+00 5.84843493e-01 1.75453048e+00 ... 5.84843493e-01\n",
      "  1.94168040e+02 1.75453048e+00]\n",
      " [4.94233937e-03 1.64744646e-03 4.94233937e-03 ... 1.64744646e-03\n",
      "  5.46952224e-01 4.94233937e-03]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2, p, dof, expected = chi2_contingency(observed)\n",
    "print(f\"Chi-squared value: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom (dof): {dof}\")\n",
    "print(f\"Expected values: {expected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74e03d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject null hypothesis - There is a significant association between the variables.\n"
     ]
    }
   ],
   "source": [
    "# Compare p-value with significance level (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"Reject null hypothesis - There is a significant association between the variables.\")\n",
    "else:\n",
    "    print(\"Failed to reject null hypothesis - There is no significant association between the variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61dbea9",
   "metadata": {},
   "source": [
    "Conclusion: We reject Null hypothesis with 95% confidence to prove that an Employee's residence is dependent on Company's location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f50ef",
   "metadata": {},
   "source": [
    "### Fisher's Exact Test\n",
    "\n",
    "Used to test the likelihood of observed values as extreme as in the given data occuring by chance. Commonly used for small sizes so small that applying Chi squared test would be inappropriate.\n",
    "\n",
    "\n",
    "Assumptions:\n",
    "It does not rely on asymptotic approximations, making it suitable for small samples.\n",
    "Appropriate when the expected cell counts in a contingency table are less than 5.\n",
    "\n",
    "\n",
    "How does it differ from Chi-squared test?\n",
    "\n",
    "Fishers's Exact differs from Chi-sq test in terms of sample size and assumptions. \n",
    "1. Sample Size Sensitivity:\n",
    "- Fisher's Exact Test is more suitable for small sample sizes, especially when dealing with 2x2 tables.\n",
    "- The Chi-squared test is more commonly used with larger sample sizes.\n",
    "2. Exact vs. Asymptotic:\n",
    "- Fisher's Exact Test calculates the exact probability of observing the data given the marginal totals.\n",
    "- The Chi-squared test relies on asymptotic approximations, making it a good choice for larger datasets.\n",
    "3. Expected Frequencies:\n",
    "- Fisher's Exact Test is preferred when expected frequencies in any cell are very low.\n",
    "- The Chi-squared test can become less reliable with small expected frequencies.\n",
    "As a rule of thumb, if the sample size is small (<20) and the expected frequencies (<5 in at least 20% of the cells) are low, Fisher's Exact Test is a safer choice. If the sample size is large, the Chi-squared test is usually appropriate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3448a69",
   "metadata": {},
   "source": [
    "#### Implementation\n",
    "Let's try to figure out if company sizes (S & L) are associated with experience level (Mid level and Entry level) of employees.\n",
    "<br/>H0: There is no association between the size of company and the experience level of employees\n",
    "<br/>Ha: There is association between  the size of company and the experience level of employees\n",
    "\n",
    "Level of significance: 0.05 (or 95% Confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eeeee056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>company_size</th>\n",
       "      <th>L</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience_level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "company_size       L   S\n",
       "experience_level        \n",
       "EN                 2   5\n",
       "MI                13  10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_test_df = hypothesis_data\\\n",
    "                .loc[((hypothesis_data.experience_level.isin(['EN', 'MI']))  \\\n",
    "                & (hypothesis_data.company_size.isin(['S', 'L'])))]\\\n",
    "                .sample(n=30) \n",
    "observed_contingeny_tb = pd.crosstab(exact_test_df['experience_level'], exact_test_df['company_size'])\n",
    "observed_contingeny_tb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "932b4edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reject null hypothesis - There is no significant association between the variables.\n"
     ]
    }
   ],
   "source": [
    "# Perform Fisher's Exact test\n",
    "odds_ratio, p_value = stats.fisher_exact(observed_contingeny_tb)\n",
    "\n",
    "print(f\"Odds-ratio: {odds_ratio}; p-value: {p_value}\")\n",
    "\n",
    "# Compare p-value with significance level (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis - There is a significant association between the variables.\")\n",
    "else:\n",
    "    print(\"Failed to reject null hypothesis - There is no significant association between the variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be0bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
